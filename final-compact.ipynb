{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # advanced plotting library\n",
    "#\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional functions\n",
    "def split_labels(data, label_feature):\n",
    "    \"\"\"\n",
    "    Split the given column of of the data, returning the full data set (without that\n",
    "    feature) and the split off feature.\n",
    "    \"\"\"\n",
    "    return data.drop(columns=label_feature), data[label_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Transformers\n",
    "class DropBadRowsTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, column_to_drop_from, value_to_drop):\n",
    "        super().__init__()\n",
    "        self.column_to_drop_from = column_to_drop_from\n",
    "        self.value_to_drop = value_to_drop\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        rows_to_drop = X[X[self.column_to_drop_from] != self.value_to_drop].index\n",
    "        X.drop(rows_to_drop, inplace=True)\n",
    "        y.drop(rows_to_drop, inplace=True)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X\n",
    "\n",
    "class ProtectXy(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Due to all the sketchy stuff the other transformers do in fit(), we\n",
    "    need a way to protect the fact that those datasets are constantly\n",
    "    changing but we don't want to change the global datasets.\n",
    "\n",
    "    All of this is to work around the limitation that the transform()\n",
    "    method doesn't have a y parameter...\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.X_ref_ = None\n",
    "        self.y_ref_ = None\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        if self.X_ref_ is X and self.y_ref_ is y:\n",
    "            X._update_inplace(self.X_copy_)\n",
    "            y._update_inplace(self.y_copy_)\n",
    "        else:\n",
    "            self.X_ref_, self.y_ref_ = X, y\n",
    "            self.X_copy_, self.y_copy_ = X.copy(), y.copy()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X): return X  # due to the need for modifying and using the y variable, the work is done above\n",
    "\n",
    "# class DropColumnsTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "#     def __init__(self, columns_to_drop):\n",
    "#         super().__init__()\n",
    "#         self.columns_to_drop = columns_to_drop\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "    \n",
    "#     def transform(self, X, y=None):\n",
    "#         # Drop the columns that we want to drop\n",
    "#         for column in self.columns_to_drop:\n",
    "#             X.drop(column, axis=1, inplace=True)\n",
    "#         return X\n",
    "\n",
    "\n",
    "class ConvertRealClassificationValuesToHumanReadableStrings(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, label_map=None):\n",
    "        super().__init__()\n",
    "        self.label_map = label_map\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Replace 'real' scores with their categorical string\n",
    "        return X.applymap(lambda x: self.label_map[x])\n",
    "\n",
    "    \n",
    "class ClassifierToNumericalValueTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_to_apply_to=None, classifications_kept=None):\n",
    "        super().__init__()\n",
    "        # Transform_columns is a list of column header strings to which to apply the transformation\n",
    "        # Classifications kept is a list of strings correlating to the classification level\n",
    "        self.features_to_apply_to = features_to_apply_to\n",
    "        self.classifications_kept = classifications_kept\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        # for feature in self.features_to_apply_to:\n",
    "        #     if y is not None and feature in y.columns:\n",
    "        #         y[feature] = y[feature].apply(lambda x: 1 if x in self.classifications_kept else 0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for feature in self.features_to_apply_to:\n",
    "            X[feature] = X[feature].apply(lambda x: 1 if x in self.classifications_kept else 0)\n",
    "        return X\n",
    "\n",
    "    \n",
    "class AddNewFeatureFromSeveralLabelsTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    # data_headers_modded['Hallucinogenic User'] = np.any([(data_headers_modded[column] == 1) for column in ['Ketamine', 'LSD', 'Mushrooms']], axis=0)\n",
    "    \"\"\"\n",
    "    def __init__(self, new_column, several_labels):\n",
    "        super().__init__()\n",
    "        self.new_column = new_column\n",
    "        self.several_labels = several_labels\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        print(self.new_column)\n",
    "        X[self.new_column] = np.any([(X[label] == 1) for label in self.several_labels], axis=0)\n",
    "        return X\n",
    "\n",
    "\n",
    "# class IsCasualDrugUserTransformer(BaseEstimator, TransformerMixin):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     def __init__(self, several_labels):\n",
    "#         super().__init__()\n",
    "#         self.several_labels = several_labels\n",
    "\n",
    "#     def fit(self, X, y=None, **kwargs):\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X, y=None):\n",
    "#         # Find all non-hard drug users who use casual drugs\n",
    "#         X['casual_drug_user'] = np.any([(X[label] == 1) for label in self.several_labels], axis=0) & ~X['hard_drug_user']\n",
    "#         return X\n",
    "\n",
    "\n",
    "class IsCollegeEducated():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.college_education = ['Bachelor\\'s', 'Master\\'s', 'Ph.D.']\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.isin(self.college_education)\n",
    "\n",
    "class IsHighSchoolDropout():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # TODO: add to the assumptions that early graduations go on to become college educated\n",
    "        self.dropout_years = ['<16 yrs old', '16 yrs old', '17 yrs old']\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.isin(self.dropout_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the display\n",
    "pd.set_option('max_columns', None)\n",
    "# Load in the data and fix the header names\n",
    "data = pd.read_csv('drug_consumption_with_headers.data')\n",
    "data = data.rename(columns=lambda x: x.strip()) # Remove extra spaces from headers\n",
    "# Split off the label we are trying to predict\n",
    "X, y = split_labels(data, 'Heroin')\n",
    "# Convert the y labels to a numerical value\n",
    "y = y.isin(['CL3', 'CL4', 'CL5', 'CL6']).astype(float)\n",
    "\n",
    "# Split off the training set from the testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# y_train = y_train.isin(['CL3', 'CL4', 'CL5', 'CL6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_labels = ['Alcohol', 'Amphet', 'Amyl', 'Benzos', 'Caff', \n",
    "              'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstacy', #'Heroin',\n",
    "              'Ketamine', 'Legalh', 'LSD', 'Meth', 'Mushrooms', \n",
    "              'Nicotine', 'VSA']\n",
    "# 'CL0' is the lowest classification level, 'CL6' is the highest\n",
    "# CL0 Never Used\n",
    "# CL1 Used over a Decade Ago\n",
    "# CL2 Used in Last Decade \n",
    "# CL3 Used in Last Year \n",
    "# CL4 Used in Last Month\n",
    "# CL5 Used in Last Week \n",
    "# CL6 Used in Last Day\n",
    "user_classifications =  ['CL3', 'CL4', 'CL5', 'CL6']\n",
    "label_map_age = {\n",
    "            -0.95197: '18-24', \n",
    "            -0.07854: '25-34', \n",
    "            0.49788: '35-44', \n",
    "            1.09449: '45-54', \n",
    "            1.82213: '55-64', \n",
    "            2.59171: '65+'\n",
    "}\n",
    "label_map_edu = {\n",
    "            -2.43591: '<16 yrs old',\n",
    "            -1.73790: '16 yrs old',\n",
    "            -1.43719: '17 yrs old',\n",
    "            -1.22751: '18 yrs old',\n",
    "            -0.61113: 'Some college or uni., no cert. or degree',\n",
    "            -0.05921: 'Prof. cert./diploma',\n",
    "            0.45468: 'Bachelor\\'s',\n",
    "            1.16365: 'Master\\'s',\n",
    "            1.98437: 'Ph.D.'\n",
    "}\n",
    "label_map_gender = {\n",
    "    -0.48246: 0,\n",
    "    0.48246: 1\n",
    "}\n",
    "edu_labels = list(label_map_edu.values())\n",
    "age_labels = list(label_map_age.values())\n",
    "all_labels = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_personality = ['Nscore (Real) [neuroticism]',\n",
    "       'Escore (Real) [Extraversion]',\n",
    "       'Oscore (Real) [Openness to experience]',\n",
    "       'Ascore (Real) [Agreeableness]', \n",
    "       'Cscore (Real) [Conscientiousness]',\n",
    "       'Impulsive (Real)', \n",
    "       'SS (Real) [sensation seeing (sic)]']\n",
    "\n",
    "labels_remaining =  ['is_college_educated', 'is_high_school_dropout'] + \\\n",
    "              list(label_map_edu.values()) + list(label_map_age.values()) + \\\n",
    "              [ 'Gender (Real)', 'Alcohol', 'Amphet', 'Amyl', 'Benzos', 'Caff', \n",
    "              'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstacy', 'Ketamine', 'Legalh', \n",
    "              'LSD', 'Meth', 'Mushrooms', 'Nicotine', 'VSA' ] + labels_personality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1501 entries, 0 to 1500\n",
      "Data columns (total 42 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   is_college_educated                       1501 non-null   float64\n",
      " 1   is_high_school_dropout                    1501 non-null   float64\n",
      " 2   <16 yrs old                               1501 non-null   float64\n",
      " 3   16 yrs old                                1501 non-null   float64\n",
      " 4   17 yrs old                                1501 non-null   float64\n",
      " 5   18 yrs old                                1501 non-null   float64\n",
      " 6   Some college or uni., no cert. or degree  1501 non-null   float64\n",
      " 7   Prof. cert./diploma                       1501 non-null   float64\n",
      " 8   Bachelor's                                1501 non-null   float64\n",
      " 9   Master's                                  1501 non-null   float64\n",
      " 10  Ph.D.                                     1501 non-null   float64\n",
      " 11  18-24                                     1501 non-null   float64\n",
      " 12  25-34                                     1501 non-null   float64\n",
      " 13  35-44                                     1501 non-null   float64\n",
      " 14  45-54                                     1501 non-null   float64\n",
      " 15  55-64                                     1501 non-null   float64\n",
      " 16  65+                                       1501 non-null   float64\n",
      " 17  Gender (Real)                             1501 non-null   float64\n",
      " 18  Alcohol                                   1501 non-null   float64\n",
      " 19  Amphet                                    1501 non-null   float64\n",
      " 20  Amyl                                      1501 non-null   float64\n",
      " 21  Benzos                                    1501 non-null   float64\n",
      " 22  Caff                                      1501 non-null   float64\n",
      " 23  Cannabis                                  1501 non-null   float64\n",
      " 24  Choc                                      1501 non-null   float64\n",
      " 25  Coke                                      1501 non-null   float64\n",
      " 26  Crack                                     1501 non-null   float64\n",
      " 27  Ecstacy                                   1501 non-null   float64\n",
      " 28  Ketamine                                  1501 non-null   float64\n",
      " 29  Legalh                                    1501 non-null   float64\n",
      " 30  LSD                                       1501 non-null   float64\n",
      " 31  Meth                                      1501 non-null   float64\n",
      " 32  Mushrooms                                 1501 non-null   float64\n",
      " 33  Nicotine                                  1501 non-null   float64\n",
      " 34  VSA                                       1501 non-null   float64\n",
      " 35  Nscore (Real) [neuroticism]               1501 non-null   float64\n",
      " 36  Escore (Real) [Extraversion]              1501 non-null   float64\n",
      " 37  Oscore (Real) [Openness to experience]    1501 non-null   float64\n",
      " 38  Ascore (Real) [Agreeableness]             1501 non-null   float64\n",
      " 39  Cscore (Real) [Conscientiousness]         1501 non-null   float64\n",
      " 40  Impulsive (Real)                          1501 non-null   float64\n",
      " 41  SS (Real) [sensation seeing (sic)]        1501 non-null   float64\n",
      "dtypes: float64(42)\n",
      "memory usage: 492.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that drops any samples with a 'Semer' value that is not CL0 and then drops the 'Semer' column\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('protect_xy', ProtectXy()),\n",
    "    ('drop_semer_samples', DropBadRowsTransformer('Semer', 'CL0')),\n",
    "    ('col_trans', ColumnTransformer(transformers=[\n",
    "        ('drop_unneeded', 'drop', ['Semer', 'ID',  'Country (Real)', 'Ethnicity (Real)']),\n",
    "        ('edu_feature_pl_college_educated', Pipeline(steps=[\n",
    "            ('convert_edu_real_values_to_human_readable_string_1', ConvertRealClassificationValuesToHumanReadableStrings(label_map=label_map_edu)),\n",
    "            ('add_new_feature_college_educated', IsCollegeEducated()),\n",
    "        ]), ['Education (Real)']),\n",
    "        ('edu_features_pl_highschool_dropout', Pipeline(steps=[\n",
    "            ('convert_edu_real_values_to_human_readable_string_1', ConvertRealClassificationValuesToHumanReadableStrings(label_map=label_map_edu)),\n",
    "            ('add_new_feature_highschool_dropout', IsHighSchoolDropout()),\n",
    "        ]), ['Education (Real)']),\n",
    "        ('edu_encoding_pl', Pipeline([\n",
    "            ('convert_edu_real_values_to_human_readable_string_2', ConvertRealClassificationValuesToHumanReadableStrings(label_map=label_map_edu)),\n",
    "            ('one_hot_encoding_edu', OneHotEncoder(drop=None, categories=[edu_labels])),\n",
    "        ]), ['Education (Real)']),\n",
    "        ('age', Pipeline([  \n",
    "            ('convert_age_real_values_to_human_readable_string', ConvertRealClassificationValuesToHumanReadableStrings(label_map=label_map_age)),\n",
    "            ('one_hot_encoding_age', OneHotEncoder(drop=None, categories=[age_labels])),\n",
    "        ]), ['Age (Real)']),\n",
    "        ('gender', Pipeline(steps=[\n",
    "            ('convert_gender_real_vals_to_binary', ConvertRealClassificationValuesToHumanReadableStrings(label_map=label_map_gender)),\n",
    "        ]), ['Gender (Real)']),\n",
    "        ('drug_classifications_to_users_pl', Pipeline(steps=[\n",
    "            ('classification_to_num_val', ClassifierToNumericalValueTransformer(features_to_apply_to=drug_labels, classifications_kept=user_classifications))]),\n",
    "        ['Alcohol', 'Amphet', 'Amyl', 'Benzos', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstacy', 'Ketamine', 'Legalh', 'LSD', 'Meth', 'Mushrooms', 'Nicotine', 'VSA']),\n",
    "    ], remainder='passthrough')),\n",
    "])\n",
    "X_trans = pd.DataFrame(pipeline.fit_transform(X_train, y_train), columns=labels_remaining)\n",
    "# X_trans = pipeline.fit_transform(X_train, y_train)\n",
    "X_trans.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.array(X_trans.copy()).astype(np.float32)\n",
    "# data_y = np.array(y_train.copy()).astype(np.float32)\n",
    "# # import tensorflow as tf\n",
    "# # X_train = tf.convert_to_tensor(data)\n",
    "# # y_train = tf.convert_to_tensor(data_y)\n",
    "# # Jeff took 5000/60000, 1/12 of the original for his validation set. We will take ~1/12 of 1501, 125\n",
    "# X_valid, X_train_subset = data[:125], data[125:]\n",
    "# y_valid, y_train_subset = data_y[:125], data_y[125:]\n",
    "\n",
    "# # Create the model using 2 hidden layers with 300 and 100 neurons using ReLU\n",
    "# model = keras.models.Sequential()\n",
    "# model.add(keras.layers.Flatten(input_shape=X_train_subset[0].shape, name=\"input\"))\n",
    "# model.add(keras.layers.BatchNormalization()) # Add after very layer\n",
    "# model.add(keras.layers.Dense(300, activation=keras.activations.relu, kernel_initializer=\"he_normal\", name=\"hidden-1\"))\n",
    "# model.add(keras.layers.BatchNormalization()) # Batch\n",
    "# model.add(keras.layers.Dense(100, activation=keras.activations.relu, name=\"hidden-2\"))\n",
    "# model.add(keras.layers.BatchNormalization()) # Batch\n",
    "# model.add(keras.layers.Dense(10, activation=keras.activations.softmax, name=\"output\"))\n",
    "\n",
    "# # Compile the model using the SGD optimizer (LR=0.01 - the default), categorical cross-entropy loss, and an accuracy metric\n",
    "# model.compile(optimizer=keras.optimizers.SGD(lr=0.01), \n",
    "#               loss=keras.losses.sparse_categorical_crossentropy, \n",
    "#               metrics=['accuracy']\n",
    "#               )\n",
    "\n",
    "# # Fit the model to the training data using 10 epochs\n",
    "# model.fit(X_train_subset, y_train_subset, epochs=10, validation_data=(X_valid, y_valid))\n",
    "\n",
    "# # Evaluate the testing performance\n",
    "# model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.2677 - accuracy: 0.5211 - val_loss: 1.6667 - val_accuracy: 0.7040\n",
      "Epoch 2/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.4171 - accuracy: 0.7355 - val_loss: 1.3874 - val_accuracy: 0.8400\n",
      "Epoch 3/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.2330 - accuracy: 0.8387 - val_loss: 1.3076 - val_accuracy: 0.8960\n",
      "Epoch 4/50\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0740 - accuracy: 0.8946 - val_loss: 1.1542 - val_accuracy: 0.9200\n",
      "Epoch 5/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.9376 - accuracy: 0.9230 - val_loss: 0.8201 - val_accuracy: 0.9200\n",
      "Epoch 6/50\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - accuracy: 0.8568 - val_loss: 0.6560 - val_accuracy: 0.8640\n",
      "Epoch 7/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.5214 - accuracy: 0.8714 - val_loss: 0.5728 - val_accuracy: 0.8960\n",
      "Epoch 8/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.8961 - val_loss: 0.5078 - val_accuracy: 0.9040\n",
      "Epoch 9/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4196 - accuracy: 0.9142 - val_loss: 0.4510 - val_accuracy: 0.8960\n",
      "Epoch 10/50\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.9273 - val_loss: 0.4202 - val_accuracy: 0.8880\n",
      "Epoch 11/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3810 - accuracy: 0.9288 - val_loss: 0.4908 - val_accuracy: 0.9200\n",
      "Epoch 12/50\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.9339 - val_loss: 0.4714 - val_accuracy: 0.9200\n",
      "Epoch 13/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3655 - accuracy: 0.9331 - val_loss: 0.3820 - val_accuracy: 0.9200\n",
      "Epoch 14/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3549 - accuracy: 0.9331 - val_loss: 0.4672 - val_accuracy: 0.9200\n",
      "Epoch 15/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3471 - accuracy: 0.9375 - val_loss: 0.4600 - val_accuracy: 0.9200\n",
      "Epoch 16/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3374 - accuracy: 0.9375 - val_loss: 0.4542 - val_accuracy: 0.9200\n",
      "Epoch 17/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3370 - accuracy: 0.9382 - val_loss: 0.4500 - val_accuracy: 0.9200\n",
      "Epoch 18/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.9397 - val_loss: 0.4584 - val_accuracy: 0.9200\n",
      "Epoch 19/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.9397 - val_loss: 0.5375 - val_accuracy: 0.9200\n",
      "Epoch 20/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3259 - accuracy: 0.9397 - val_loss: 0.5356 - val_accuracy: 0.9200\n",
      "Epoch 21/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.9397 - val_loss: 0.5319 - val_accuracy: 0.9200\n",
      "Epoch 22/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3165 - accuracy: 0.9397 - val_loss: 0.5284 - val_accuracy: 0.9120\n",
      "Epoch 23/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3128 - accuracy: 0.9397 - val_loss: 0.5259 - val_accuracy: 0.9120\n",
      "Epoch 24/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3104 - accuracy: 0.9397 - val_loss: 0.5255 - val_accuracy: 0.9120\n",
      "Epoch 25/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3070 - accuracy: 0.9397 - val_loss: 0.5237 - val_accuracy: 0.9120\n",
      "Epoch 26/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3040 - accuracy: 0.9397 - val_loss: 0.5213 - val_accuracy: 0.9120\n",
      "Epoch 27/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3018 - accuracy: 0.9397 - val_loss: 0.5211 - val_accuracy: 0.9120\n",
      "Epoch 28/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2997 - accuracy: 0.9397 - val_loss: 0.5191 - val_accuracy: 0.9120\n",
      "Epoch 29/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2976 - accuracy: 0.9397 - val_loss: 0.5184 - val_accuracy: 0.9120\n",
      "Epoch 30/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2959 - accuracy: 0.9397 - val_loss: 0.5176 - val_accuracy: 0.9120\n",
      "Epoch 31/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2942 - accuracy: 0.9397 - val_loss: 0.5165 - val_accuracy: 0.9120\n",
      "Epoch 32/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2924 - accuracy: 0.9397 - val_loss: 0.5149 - val_accuracy: 0.9120\n",
      "Epoch 33/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2911 - accuracy: 0.9397 - val_loss: 0.5145 - val_accuracy: 0.9120\n",
      "Epoch 34/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2898 - accuracy: 0.9397 - val_loss: 0.5137 - val_accuracy: 0.9120\n",
      "Epoch 35/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2884 - accuracy: 0.9397 - val_loss: 0.5131 - val_accuracy: 0.9120\n",
      "Epoch 36/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2870 - accuracy: 0.9397 - val_loss: 0.5119 - val_accuracy: 0.9120\n",
      "Epoch 37/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2860 - accuracy: 0.9397 - val_loss: 0.5119 - val_accuracy: 0.9120\n",
      "Epoch 38/50\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2850 - accuracy: 0.9397 - val_loss: 0.4359 - val_accuracy: 0.9120\n",
      "Epoch 39/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2842 - accuracy: 0.9397 - val_loss: 0.4202 - val_accuracy: 0.9120\n",
      "Epoch 40/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2830 - accuracy: 0.9397 - val_loss: 0.5095 - val_accuracy: 0.9120\n",
      "Epoch 41/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2825 - accuracy: 0.9397 - val_loss: 0.4118 - val_accuracy: 0.9120\n",
      "Epoch 42/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2567 - accuracy: 0.9397 - val_loss: 0.2924 - val_accuracy: 0.9120\n",
      "Epoch 43/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2528 - accuracy: 0.9390 - val_loss: 0.2226 - val_accuracy: 0.9120\n",
      "Epoch 44/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.9390 - val_loss: 0.2932 - val_accuracy: 0.9120\n",
      "Epoch 45/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2354 - accuracy: 0.9397 - val_loss: 0.2866 - val_accuracy: 0.9120\n",
      "Epoch 46/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2388 - accuracy: 0.9397 - val_loss: 0.2850 - val_accuracy: 0.9120\n",
      "Epoch 47/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2372 - accuracy: 0.9397 - val_loss: 0.2843 - val_accuracy: 0.9120\n",
      "Epoch 48/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2361 - accuracy: 0.9397 - val_loss: 0.2833 - val_accuracy: 0.9120\n",
      "Epoch 49/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2347 - accuracy: 0.9397 - val_loss: 0.2824 - val_accuracy: 0.9120\n",
      "Epoch 50/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2335 - accuracy: 0.9397 - val_loss: 0.2816 - val_accuracy: 0.9120\n"
     ]
    }
   ],
   "source": [
    "# Cell above keeps breakingn so I'm trying this a different way\n",
    "data = np.array(X_trans.copy()).astype(np.float32)\n",
    "data_y = np.array(y_train.copy()).astype(np.float32)\n",
    "# Jeff took 5000/60000, 1/12 of the original for his validation set. We will take ~1/12 of 1501, 125\n",
    "X_valid, X_train_subset = data[:125], data[125:]\n",
    "y_valid, y_train_subset = data_y[:125], data_y[125:]\n",
    "\n",
    "# Create the layers for the deep and wide model\n",
    "input_ = keras.layers.Input(shape=X_train_subset[0].shape)\n",
    "hidden1 = keras.layers.Dense(300, activation=\"relu\")\n",
    "hidden2 = keras.layers.Dense(100, activation=\"relu\")\n",
    "concat = keras.layers.Concatenate()\n",
    "output_layer = keras.layers.Dense(10)\n",
    "\n",
    "# Create the connections between the layers\n",
    "output = hidden1(input_)\n",
    "output = hidden2(output)\n",
    "output = concat([input_, output])\n",
    "output = output_layer(output)\n",
    "\n",
    "# Create the model\n",
    "model = keras.Model(inputs=[input_], outputs=[output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              loss=keras.losses.sparse_categorical_crossentropy, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train_subset, y_train_subset, validation_data=(X_valid, y_valid), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_neurons=100, n_hidden_layers=3, learning_rate=0.01):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=X_train[0].shape))\n",
    "    for _ in range(n_hidden_layers):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "                  loss=\"mse\")\n",
    "\n",
    "    # This method must return the compiled, but not fit, model\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
