{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # advanced plotting library\n",
    "#\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional functions\n",
    "def split_labels(data, label_feature):\n",
    "    \"\"\"\n",
    "    Split the given column of of the data, returning the full data set (without that\n",
    "    feature) and the split off feature.\n",
    "    \"\"\"\n",
    "    return data.drop(columns=label_feature), data[label_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Transformers\n",
    "class DropBadRowsTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, column_to_drop_from, value_to_drop):\n",
    "        super().__init__()\n",
    "        self.column_to_drop_from = column_to_drop_from\n",
    "        self.value_to_drop = value_to_drop\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        rows_to_drop = X[X[self.column_to_drop_from] != self.value_to_drop].index\n",
    "        X.drop(rows_to_drop, inplace=True)\n",
    "        y.drop(rows_to_drop, inplace=True)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X\n",
    "\n",
    "class ProtectXy(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Due to all the sketchy stuff the other transformers do in fit(), we\n",
    "    need a way to protect the fact that those datasets are constantly\n",
    "    changing but we don't want to change the global datasets.\n",
    "\n",
    "    All of this is to work around the limitation that the transform()\n",
    "    method doesn't have a y parameter...\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.X_ref_ = None\n",
    "        self.y_ref_ = None\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        if self.X_ref_ is X and self.y_ref_ is y:\n",
    "            X._update_inplace(self.X_copy_)\n",
    "            y._update_inplace(self.y_copy_)\n",
    "        else:\n",
    "            self.X_ref_, self.y_ref_ = X, y\n",
    "            self.X_copy_, self.y_copy_ = X.copy(), y.copy()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X): return X  # due to the need for modifying and using the y variable, the work is done above\n",
    "\n",
    "# class DropColumnsTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "#     def __init__(self, columns_to_drop):\n",
    "#         super().__init__()\n",
    "#         self.columns_to_drop = columns_to_drop\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "    \n",
    "#     def transform(self, X, y=None):\n",
    "#         # Drop the columns that we want to drop\n",
    "#         for column in self.columns_to_drop:\n",
    "#             X.drop(column, axis=1, inplace=True)\n",
    "#         return X\n",
    "\n",
    "\n",
    "class ConvertRealClassificationValuesToHumanReadableStrings(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, label_map=None):\n",
    "        super().__init__()\n",
    "        self.label_map = label_map\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Replace 'real' scores with their categorical string\n",
    "        return X.applymap(lambda x: self.label_map[x])\n",
    "\n",
    "    \n",
    "class ClassifierToNumericalValueTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_to_apply_to=None, classifications_kept=None):\n",
    "        super().__init__()\n",
    "        # Transform_columns is a list of column header strings to which to apply the transformation\n",
    "        # Classifications kept is a list of strings correlating to the classification level\n",
    "        self.features_to_apply_to = features_to_apply_to\n",
    "        self.classifications_kept = classifications_kept\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        # for feature in self.features_to_apply_to:\n",
    "        #     if y is not None and feature in y.columns:\n",
    "        #         y[feature] = y[feature].apply(lambda x: 1 if x in self.classifications_kept else 0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for feature in self.features_to_apply_to:\n",
    "            X[feature] = X[feature].apply(lambda x: 1 if x in self.classifications_kept else 0)\n",
    "        return X\n",
    "\n",
    "    \n",
    "class AddNewFeatureFromSeveralLabelsTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    # data_headers_modded['Hallucinogenic User'] = np.any([(data_headers_modded[column] == 1) for column in ['Ketamine', 'LSD', 'Mushrooms']], axis=0)\n",
    "    \"\"\"\n",
    "    def __init__(self, new_column, several_labels):\n",
    "        super().__init__()\n",
    "        self.new_column = new_column\n",
    "        self.several_labels = several_labels\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        print(self.new_column)\n",
    "        X[self.new_column] = np.any([(X[label] == 1) for label in self.several_labels], axis=0)\n",
    "        return X\n",
    "\n",
    "\n",
    "# class IsCasualDrugUserTransformer(BaseEstimator, TransformerMixin):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     def __init__(self, several_labels):\n",
    "#         super().__init__()\n",
    "#         self.several_labels = several_labels\n",
    "\n",
    "#     def fit(self, X, y=None, **kwargs):\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X, y=None):\n",
    "#         # Find all non-hard drug users who use casual drugs\n",
    "#         X['casual_drug_user'] = np.any([(X[label] == 1) for label in self.several_labels], axis=0) & ~X['hard_drug_user']\n",
    "#         return X\n",
    "\n",
    "\n",
    "class IsCollegeEducated():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.college_education = ['Bachelor\\'s', 'Master\\'s', 'Ph.D.']\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.isin(self.college_education)\n",
    "\n",
    "class IsHighSchoolDropout():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # TODO: add to the assumptions that early graduations go on to become college educated\n",
    "        self.dropout_years = ['<16 yrs old', '16 yrs old', '17 yrs old']\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.isin(self.dropout_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the display\n",
    "pd.set_option('max_columns', None)\n",
    "# Load in the data and fix the header names\n",
    "data = pd.read_csv('drug_consumption_with_headers.data')\n",
    "data = data.rename(columns=lambda x: x.strip()) # Remove extra spaces from headers\n",
    "# Split off the label we are trying to predict\n",
    "X, y = split_labels(data, 'Heroin')\n",
    "# Convert the y labels to a numerical value\n",
    "y = y.isin(['CL3', 'CL4', 'CL5', 'CL6']).astype(float)\n",
    "\n",
    "# Split off the training set from the testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# y_train = y_train.isin(['CL3', 'CL4', 'CL5', 'CL6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_labels = ['Alcohol', 'Amphet', 'Amyl', 'Benzos', 'Caff', \n",
    "              'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstacy', #'Heroin',\n",
    "              'Ketamine', 'Legalh', 'LSD', 'Meth', 'Mushrooms', \n",
    "              'Nicotine', 'VSA']\n",
    "# 'CL0' is the lowest classification level, 'CL6' is the highest\n",
    "# CL0 Never Used\n",
    "# CL1 Used over a Decade Ago\n",
    "# CL2 Used in Last Decade \n",
    "# CL3 Used in Last Year \n",
    "# CL4 Used in Last Month\n",
    "# CL5 Used in Last Week \n",
    "# CL6 Used in Last Day\n",
    "user_classifications =  ['CL3', 'CL4', 'CL5', 'CL6']\n",
    "label_map_age = {\n",
    "            -0.95197: '18-24', \n",
    "            -0.07854: '25-34', \n",
    "            0.49788: '35-44', \n",
    "            1.09449: '45-54', \n",
    "            1.82213: '55-64', \n",
    "            2.59171: '65+'\n",
    "}\n",
    "label_map_edu = {\n",
    "            -2.43591: '<16 yrs old',\n",
    "            -1.73790: '16 yrs old',\n",
    "            -1.43719: '17 yrs old',\n",
    "            -1.22751: '18 yrs old',\n",
    "            -0.61113: 'Some college or uni., no cert. or degree',\n",
    "            -0.05921: 'Prof. cert./diploma',\n",
    "            0.45468: 'Bachelor\\'s',\n",
    "            1.16365: 'Master\\'s',\n",
    "            1.98437: 'Ph.D.'\n",
    "}\n",
    "label_map_gender = {\n",
    "    -0.48246: 0,\n",
    "    0.48246: 1\n",
    "}\n",
    "edu_labels = list(label_map_edu.values())\n",
    "age_labels = list(label_map_age.values())\n",
    "all_labels = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_personality = ['Nscore (Real) [neuroticism]',\n",
    "       'Escore (Real) [Extraversion]',\n",
    "       'Oscore (Real) [Openness to experience]',\n",
    "       'Ascore (Real) [Agreeableness]', \n",
    "       'Cscore (Real) [Conscientiousness]',\n",
    "       'Impulsive (Real)', \n",
    "       'SS (Real) [sensation seeing (sic)]']\n",
    "\n",
    "labels_remaining =  ['is_college_educated', 'is_high_school_dropout'] + \\\n",
    "              list(label_map_edu.values()) + list(label_map_age.values()) + \\\n",
    "              [ 'Gender (Real)', 'Alcohol', 'Amphet', 'Amyl', 'Benzos', 'Caff', \n",
    "              'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstacy', 'Ketamine', 'Legalh', \n",
    "              'LSD', 'Meth', 'Mushrooms', 'Nicotine', 'VSA' ] + labels_personality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1501 entries, 0 to 1500\n",
      "Data columns (total 42 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   is_college_educated                       1501 non-null   float64\n",
      " 1   is_high_school_dropout                    1501 non-null   float64\n",
      " 2   <16 yrs old                               1501 non-null   float64\n",
      " 3   16 yrs old                                1501 non-null   float64\n",
      " 4   17 yrs old                                1501 non-null   float64\n",
      " 5   18 yrs old                                1501 non-null   float64\n",
      " 6   Some college or uni., no cert. or degree  1501 non-null   float64\n",
      " 7   Prof. cert./diploma                       1501 non-null   float64\n",
      " 8   Bachelor's                                1501 non-null   float64\n",
      " 9   Master's                                  1501 non-null   float64\n",
      " 10  Ph.D.                                     1501 non-null   float64\n",
      " 11  18-24                                     1501 non-null   float64\n",
      " 12  25-34                                     1501 non-null   float64\n",
      " 13  35-44                                     1501 non-null   float64\n",
      " 14  45-54                                     1501 non-null   float64\n",
      " 15  55-64                                     1501 non-null   float64\n",
      " 16  65+                                       1501 non-null   float64\n",
      " 17  Gender (Real)                             1501 non-null   float64\n",
      " 18  Alcohol                                   1501 non-null   float64\n",
      " 19  Amphet                                    1501 non-null   float64\n",
      " 20  Amyl                                      1501 non-null   float64\n",
      " 21  Benzos                                    1501 non-null   float64\n",
      " 22  Caff                                      1501 non-null   float64\n",
      " 23  Cannabis                                  1501 non-null   float64\n",
      " 24  Choc                                      1501 non-null   float64\n",
      " 25  Coke                                      1501 non-null   float64\n",
      " 26  Crack                                     1501 non-null   float64\n",
      " 27  Ecstacy                                   1501 non-null   float64\n",
      " 28  Ketamine                                  1501 non-null   float64\n",
      " 29  Legalh                                    1501 non-null   float64\n",
      " 30  LSD                                       1501 non-null   float64\n",
      " 31  Meth                                      1501 non-null   float64\n",
      " 32  Mushrooms                                 1501 non-null   float64\n",
      " 33  Nicotine                                  1501 non-null   float64\n",
      " 34  VSA                                       1501 non-null   float64\n",
      " 35  Nscore (Real) [neuroticism]               1501 non-null   float64\n",
      " 36  Escore (Real) [Extraversion]              1501 non-null   float64\n",
      " 37  Oscore (Real) [Openness to experience]    1501 non-null   float64\n",
      " 38  Ascore (Real) [Agreeableness]             1501 non-null   float64\n",
      " 39  Cscore (Real) [Conscientiousness]         1501 non-null   float64\n",
      " 40  Impulsive (Real)                          1501 non-null   float64\n",
      " 41  SS (Real) [sensation seeing (sic)]        1501 non-null   float64\n",
      "dtypes: float64(42)\n",
      "memory usage: 492.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that drops any samples with a 'Semer' value that is not CL0 and then drops the 'Semer' column\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('protect_xy', ProtectXy()),\n",
    "    ('drop_semer_samples', DropBadRowsTransformer('Semer', 'CL0')),\n",
    "    ('col_trans', ColumnTransformer(transformers=[\n",
    "        ('drop_unneeded', 'drop', ['Semer', 'ID',  'Country (Real)', 'Ethnicity (Real)']),\n",
    "        ('edu_feature_pl_college_educated', Pipeline(steps=[\n",
    "            ('convert_edu_real_values_to_human_readable_string_1', ConvertRealClassificationValuesToHumanReadableStrings(label_map=label_map_edu)),\n",
    "            ('add_new_feature_college_educated', IsCollegeEducated()),\n",
    "        ]), ['Education (Real)']),\n",
    "        ('edu_features_pl_highschool_dropout', Pipeline(steps=[\n",
    "            ('convert_edu_real_values_to_human_readable_string_1', ConvertRealClassificationValuesToHumanReadableStrings(label_map=label_map_edu)),\n",
    "            ('add_new_feature_highschool_dropout', IsHighSchoolDropout()),\n",
    "        ]), ['Education (Real)']),\n",
    "        ('edu_encoding_pl', Pipeline([\n",
    "            ('convert_edu_real_values_to_human_readable_string_2', ConvertRealClassificationValuesToHumanReadableStrings(label_map=label_map_edu)),\n",
    "            ('one_hot_encoding_edu', OneHotEncoder(drop=None, categories=[edu_labels])),\n",
    "        ]), ['Education (Real)']),\n",
    "        ('age', Pipeline([  \n",
    "            ('convert_age_real_values_to_human_readable_string', ConvertRealClassificationValuesToHumanReadableStrings(label_map=label_map_age)),\n",
    "            ('one_hot_encoding_age', OneHotEncoder(drop=None, categories=[age_labels])),\n",
    "        ]), ['Age (Real)']),\n",
    "        ('gender', Pipeline(steps=[\n",
    "            ('convert_gender_real_vals_to_binary', ConvertRealClassificationValuesToHumanReadableStrings(label_map=label_map_gender)),\n",
    "        ]), ['Gender (Real)']),\n",
    "        ('drug_classifications_to_users_pl', Pipeline(steps=[\n",
    "            ('classification_to_num_val', ClassifierToNumericalValueTransformer(features_to_apply_to=drug_labels, classifications_kept=user_classifications))]),\n",
    "        ['Alcohol', 'Amphet', 'Amyl', 'Benzos', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstacy', 'Ketamine', 'Legalh', 'LSD', 'Meth', 'Mushrooms', 'Nicotine', 'VSA']),\n",
    "    ], remainder='passthrough')),\n",
    "])\n",
    "X_trans = pd.DataFrame(pipeline.fit_transform(X_train, y_train), columns=labels_remaining)\n",
    "# X_trans = pipeline.fit_transform(X_train, y_train)\n",
    "X_trans.info()\n",
    "# X_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.5082 - accuracy: 0.5610 - val_loss: 0.9908 - val_accuracy: 0.8720\n",
      "Epoch 2/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.7566 - accuracy: 0.9193 - val_loss: 0.6125 - val_accuracy: 0.9120\n",
      "Epoch 3/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4983 - accuracy: 0.9390 - val_loss: 0.4881 - val_accuracy: 0.9120\n",
      "Epoch 4/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3986 - accuracy: 0.9390 - val_loss: 0.4329 - val_accuracy: 0.9120\n",
      "Epoch 5/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3484 - accuracy: 0.9390 - val_loss: 0.4001 - val_accuracy: 0.9120\n",
      "Epoch 6/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3175 - accuracy: 0.9390 - val_loss: 0.3767 - val_accuracy: 0.9120\n",
      "Epoch 7/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2957 - accuracy: 0.9397 - val_loss: 0.3580 - val_accuracy: 0.9120\n",
      "Epoch 8/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2792 - accuracy: 0.9397 - val_loss: 0.3424 - val_accuracy: 0.9120\n",
      "Epoch 9/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2659 - accuracy: 0.9390 - val_loss: 0.3291 - val_accuracy: 0.9120\n",
      "Epoch 10/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2551 - accuracy: 0.9390 - val_loss: 0.3180 - val_accuracy: 0.9120\n",
      "Epoch 11/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.9390 - val_loss: 0.3086 - val_accuracy: 0.9120\n",
      "Epoch 12/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2387 - accuracy: 0.9390 - val_loss: 0.3001 - val_accuracy: 0.9120\n",
      "Epoch 13/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2323 - accuracy: 0.9390 - val_loss: 0.2923 - val_accuracy: 0.9120\n",
      "Epoch 14/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2267 - accuracy: 0.9397 - val_loss: 0.2862 - val_accuracy: 0.9120\n",
      "Epoch 15/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2218 - accuracy: 0.9397 - val_loss: 0.2804 - val_accuracy: 0.9120\n",
      "Epoch 16/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2175 - accuracy: 0.9397 - val_loss: 0.2749 - val_accuracy: 0.9120\n",
      "Epoch 17/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2137 - accuracy: 0.9404 - val_loss: 0.2703 - val_accuracy: 0.9120\n",
      "Epoch 18/50\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9404 - val_loss: 0.2660 - val_accuracy: 0.9120\n",
      "Epoch 19/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2072 - accuracy: 0.9404 - val_loss: 0.2622 - val_accuracy: 0.9120\n",
      "Epoch 20/50\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9404 - val_loss: 0.2589 - val_accuracy: 0.9120\n",
      "Epoch 21/50\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.9411 - val_loss: 0.2561 - val_accuracy: 0.9120\n",
      "Epoch 22/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1994 - accuracy: 0.9411 - val_loss: 0.2529 - val_accuracy: 0.9120\n",
      "Epoch 23/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1972 - accuracy: 0.9419 - val_loss: 0.2504 - val_accuracy: 0.9120\n",
      "Epoch 24/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.9426 - val_loss: 0.2475 - val_accuracy: 0.9120\n",
      "Epoch 25/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.9440 - val_loss: 0.2453 - val_accuracy: 0.9120\n",
      "Epoch 26/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1914 - accuracy: 0.9448 - val_loss: 0.2429 - val_accuracy: 0.9120\n",
      "Epoch 27/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.9455 - val_loss: 0.2405 - val_accuracy: 0.9120\n",
      "Epoch 28/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.9440 - val_loss: 0.2385 - val_accuracy: 0.9120\n",
      "Epoch 29/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.9440 - val_loss: 0.2367 - val_accuracy: 0.9120\n",
      "Epoch 30/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.9440 - val_loss: 0.2349 - val_accuracy: 0.9120\n",
      "Epoch 31/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.9440 - val_loss: 0.2330 - val_accuracy: 0.9120\n",
      "Epoch 32/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.9440 - val_loss: 0.2313 - val_accuracy: 0.9120\n",
      "Epoch 33/50\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9448 - val_loss: 0.2296 - val_accuracy: 0.9120\n",
      "Epoch 34/50\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1799 - accuracy: 0.9440 - val_loss: 0.2279 - val_accuracy: 0.9120\n",
      "Epoch 35/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1787 - accuracy: 0.9419 - val_loss: 0.2268 - val_accuracy: 0.9120\n",
      "Epoch 36/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1776 - accuracy: 0.9426 - val_loss: 0.2255 - val_accuracy: 0.9120\n",
      "Epoch 37/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1765 - accuracy: 0.9426 - val_loss: 0.2242 - val_accuracy: 0.9120\n",
      "Epoch 38/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.9433 - val_loss: 0.2228 - val_accuracy: 0.9120\n",
      "Epoch 39/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.9455 - val_loss: 0.2213 - val_accuracy: 0.9120\n",
      "Epoch 40/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1735 - accuracy: 0.9433 - val_loss: 0.2204 - val_accuracy: 0.9120\n",
      "Epoch 41/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1727 - accuracy: 0.9440 - val_loss: 0.2196 - val_accuracy: 0.9120\n",
      "Epoch 42/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1718 - accuracy: 0.9455 - val_loss: 0.2183 - val_accuracy: 0.9120\n",
      "Epoch 43/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1710 - accuracy: 0.9440 - val_loss: 0.2173 - val_accuracy: 0.9120\n",
      "Epoch 44/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1701 - accuracy: 0.9455 - val_loss: 0.2163 - val_accuracy: 0.9120\n",
      "Epoch 45/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1694 - accuracy: 0.9455 - val_loss: 0.2151 - val_accuracy: 0.9200\n",
      "Epoch 46/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1685 - accuracy: 0.9455 - val_loss: 0.2142 - val_accuracy: 0.9200\n",
      "Epoch 47/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1679 - accuracy: 0.9448 - val_loss: 0.2130 - val_accuracy: 0.9200\n",
      "Epoch 48/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1671 - accuracy: 0.9448 - val_loss: 0.2124 - val_accuracy: 0.9200\n",
      "Epoch 49/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1664 - accuracy: 0.9448 - val_loss: 0.2116 - val_accuracy: 0.9200\n",
      "Epoch 50/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1657 - accuracy: 0.9455 - val_loss: 0.2107 - val_accuracy: 0.9200\n"
     ]
    }
   ],
   "source": [
    "data = np.array(X_trans.copy()).astype(np.float32)\n",
    "data_y = np.array(y_train.copy()).astype(np.float32)\n",
    "\n",
    "# Jeff took 5000/60000, 1/12 of the original for his validation set. We will take ~1/12 of 1501, 125\n",
    "X_valid, X_train_subset = data[:125], data[125:]\n",
    "y_valid, y_train_subset = data_y[:125], data_y[125:]\n",
    "\n",
    "# Create the layers for the deep and wide model\n",
    "input_ = keras.layers.Input(shape=X_train_subset[0].shape)\n",
    "hidden1 = keras.layers.Dense(300, activation=\"selu\", kernel_initializer='lecun_normal')\n",
    "hidden2 = keras.layers.Dense(100, activation=\"selu\")\n",
    "hidden3 = keras.layers.LeakyReLU(alpha=0.1)\n",
    "concat = keras.layers.Concatenate()\n",
    "output_layer = keras.layers.Dense(10, activation=\"softmax\")\n",
    "\n",
    "# Create the connections between the layers\n",
    "output = hidden1(input_)\n",
    "output = hidden2(output)\n",
    "output = hidden3(output)\n",
    "output = concat([input_, output])\n",
    "output = output_layer(output)\n",
    "\n",
    "# Create the model\n",
    "model = keras.Model(inputs=[input_], outputs=[output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              loss=keras.losses.sparse_categorical_crossentropy, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train_subset, y_train_subset, validation_data=(X_valid, y_valid), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1498 - accuracy: 0.9468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14975959062576294, 0.9468085169792175]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the X_test (and y_test) data for evaluating the model\n",
    "X_test = pd.DataFrame(pipeline.fit_transform(X_test, y_test), columns=labels_remaining)\n",
    "test_data = np.array(X_test.copy()).astype(np.float32)\n",
    "test_data_y = np.array(y_test.copy()).astype(np.float32)\n",
    "# Evaluate the models\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
