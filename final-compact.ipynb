{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # advanced plotting library\n",
    "#\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional functions\n",
    "def split_labels(data, label_feature):\n",
    "    \"\"\"\n",
    "    Split the given column of of the data, returning the full data set (without that\n",
    "    feature) and the split off feature.\n",
    "    \"\"\"\n",
    "    return data.drop(columns=label_feature), data[label_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Transformers\n",
    "class DropBadRowsTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, column_to_drop_from, value_to_drop):\n",
    "        super().__init__()\n",
    "        self.column_to_drop_from = column_to_drop_from\n",
    "        self.value_to_drop = value_to_drop\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        rows_to_drop = X[X[self.column_to_drop_from] != self.value_to_drop].index\n",
    "        X.drop(rows_to_drop, inplace=True)\n",
    "        y.drop(rows_to_drop, inplace=True)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X\n",
    "\n",
    "class ProtectXy(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Due to all the sketchy stuff the other transformers do in fit(), we\n",
    "    need a way to protect the fact that those datasets are constantly\n",
    "    changing but we don't want to change the global datasets.\n",
    "\n",
    "    All of this is to work around the limitation that the transform()\n",
    "    method doesn't have a y parameter...\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.X_ref_ = None\n",
    "        self.y_ref_ = None\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        if self.X_ref_ is X and self.y_ref_ is y:\n",
    "            X._update_inplace(self.X_copy_)\n",
    "            y._update_inplace(self.y_copy_)\n",
    "        else:\n",
    "            self.X_ref_, self.y_ref_ = X, y\n",
    "            self.X_copy_, self.y_copy_ = X.copy(), y.copy()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X): return X  # due to the need for modifying and using the y variable, the work is done above\n",
    "\n",
    "# class DropColumnsTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "#     def __init__(self, columns_to_drop):\n",
    "#         super().__init__()\n",
    "#         self.columns_to_drop = columns_to_drop\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "    \n",
    "#     def transform(self, X, y=None):\n",
    "#         # Drop the columns that we want to drop\n",
    "#         for column in self.columns_to_drop:\n",
    "#             X.drop(column, axis=1, inplace=True)\n",
    "#         return X\n",
    "\n",
    "\n",
    "class ConvertRealClassificationValuesToHumanReadableStrings(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, label_map=None):\n",
    "        super().__init__()\n",
    "        self.label_map = label_map\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Replace 'real' scores with their categorical string\n",
    "        return X.applymap(lambda x: self.label_map[x])\n",
    "\n",
    "    \n",
    "class ClassifierToNumericalValueTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_to_apply_to=None, classifications_kept=None):\n",
    "        super().__init__()\n",
    "        # Transform_columns is a list of column header strings to which to apply the transformation\n",
    "        # Classifications kept is a list of strings correlating to the classification level\n",
    "        self.features_to_apply_to = features_to_apply_to\n",
    "        self.classifications_kept = classifications_kept\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        # for feature in self.features_to_apply_to:\n",
    "        #     if y is not None and feature in y.columns:\n",
    "        #         y[feature] = y[feature].apply(lambda x: 1 if x in self.classifications_kept else 0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for feature in self.features_to_apply_to:\n",
    "            X[feature] = X[feature].apply(lambda x: 1 if x in self.classifications_kept else 0)\n",
    "        return X\n",
    "\n",
    "    \n",
    "class AddNewFeatureFromSeveralLabelsTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    # data_headers_modded['Hallucinogenic User'] = np.any([(data_headers_modded[column] == 1) for column in ['Ketamine', 'LSD', 'Mushrooms']], axis=0)\n",
    "    \"\"\"\n",
    "    def __init__(self, new_column, several_labels):\n",
    "        super().__init__()\n",
    "        self.new_column = new_column\n",
    "        self.several_labels = several_labels\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        print(self.new_column)\n",
    "        X[self.new_column] = np.any([(X[label] == 1) for label in self.several_labels], axis=0)\n",
    "        return X\n",
    "\n",
    "\n",
    "# class IsCasualDrugUserTransformer(BaseEstimator, TransformerMixin):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     def __init__(self, several_labels):\n",
    "#         super().__init__()\n",
    "#         self.several_labels = several_labels\n",
    "\n",
    "#     def fit(self, X, y=None, **kwargs):\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X, y=None):\n",
    "#         # Find all non-hard drug users who use casual drugs\n",
    "#         X['casual_drug_user'] = np.any([(X[label] == 1) for label in self.several_labels], axis=0) & ~X['hard_drug_user']\n",
    "#         return X\n",
    "\n",
    "\n",
    "class IsCollegeEducated():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.college_education = ['Bachelor\\'s', 'Master\\'s', 'Ph.D.']\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.isin(self.college_education)\n",
    "\n",
    "class IsHighSchoolDropout():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # TODO: add to the assumptions that early graduations go on to become college educated\n",
    "        self.dropout_years = ['<16 yrs old', '16 yrs old', '17 yrs old']\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.isin(self.dropout_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the display\n",
    "pd.set_option('max_columns', None)\n",
    "# Load in the data and fix the header names\n",
    "data = pd.read_csv('drug_consumption_with_headers.data')\n",
    "data = data.rename(columns=lambda x: x.strip()) # Remove extra spaces from headers\n",
    "# Split off the label we are trying to predict\n",
    "X, y = split_labels(data, 'Heroin')\n",
    "# Split off the training set from the testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_labels = ['Alcohol', 'Amphet', 'Amyl', 'Benzos', 'Caff', \n",
    "              'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstacy', #'Heroin',\n",
    "              'Ketamine', 'Legalh', 'LSD', 'Meth', 'Mushrooms', \n",
    "              'Nicotine', 'VSA']\n",
    "# 'CL0' is the lowest classification level, 'CL6' is the highest\n",
    "# CL0 Never Used\n",
    "# CL1 Used over a Decade Ago\n",
    "# CL2 Used in Last Decade \n",
    "# CL3 Used in Last Year \n",
    "# CL4 Used in Last Month\n",
    "# CL5 Used in Last Week \n",
    "# CL6 Used in Last Day\n",
    "user_classifications =  ['CL3', 'CL4', 'CL5', 'CL6']\n",
    "label_map_age = {\n",
    "            -0.95197: '18-24', \n",
    "            -0.07854: '25-34', \n",
    "            0.49788: '35-44', \n",
    "            1.09449: '45-54', \n",
    "            1.82213: '55-64', \n",
    "            2.59171: '65+'\n",
    "}\n",
    "label_map_edu = {\n",
    "            -2.43591: '<16 yrs old',\n",
    "            -1.73790: '16 yrs old',\n",
    "            -1.43719: '17 yrs old',\n",
    "            -1.22751: '18 yrs old',\n",
    "            -0.61113: 'Some college or uni., no cert. or degree',\n",
    "            -0.05921: 'Prof. cert./diploma',\n",
    "            0.45468: 'Bachelor\\'s',\n",
    "            1.16365: 'Master\\'s',\n",
    "            1.98437: 'Ph.D.'\n",
    "}\n",
    "label_map_gender = {\n",
    "    -0.48246: 0,\n",
    "    0.48246: 1\n",
    "}\n",
    "edu_labels = list(label_map_edu.values())\n",
    "age_labels = list(label_map_age.values())\n",
    "all_labels = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_personality = ['Nscore (Real) [neuroticism]',\n",
    "       'Escore (Real) [Extraversion]',\n",
    "       'Oscore (Real) [Openness to experience]',\n",
    "       'Ascore (Real) [Agreeableness]', \n",
    "       'Cscore (Real) [Conscientiousness]',\n",
    "       'Impulsive (Real)', \n",
    "       'SS (Real) [sensation seeing (sic)]']\n",
    "\n",
    "labels_remaining =  ['is_college_educated', 'is_high_school_dropout'] + \\\n",
    "              list(label_map_edu.values()) + list(label_map_age.values()) + \\\n",
    "              [ 'Gender (Real)', 'Alcohol', 'Amphet', 'Amyl', 'Benzos', 'Caff', \n",
    "              'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstacy', 'Ketamine', 'Legalh', \n",
    "              'LSD', 'Meth', 'Mushrooms', 'Nicotine', 'VSA' ] + labels_personality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_college_educated</th>\n",
       "      <th>is_high_school_dropout</th>\n",
       "      <th>&lt;16 yrs old</th>\n",
       "      <th>16 yrs old</th>\n",
       "      <th>17 yrs old</th>\n",
       "      <th>18 yrs old</th>\n",
       "      <th>Some college or uni., no cert. or degree</th>\n",
       "      <th>Prof. cert./diploma</th>\n",
       "      <th>Bachelor's</th>\n",
       "      <th>Master's</th>\n",
       "      <th>Ph.D.</th>\n",
       "      <th>18-24</th>\n",
       "      <th>25-34</th>\n",
       "      <th>35-44</th>\n",
       "      <th>45-54</th>\n",
       "      <th>55-64</th>\n",
       "      <th>65+</th>\n",
       "      <th>Gender (Real)</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Amphet</th>\n",
       "      <th>Amyl</th>\n",
       "      <th>Benzos</th>\n",
       "      <th>Caff</th>\n",
       "      <th>Cannabis</th>\n",
       "      <th>Choc</th>\n",
       "      <th>Coke</th>\n",
       "      <th>Crack</th>\n",
       "      <th>Ecstacy</th>\n",
       "      <th>Ketamine</th>\n",
       "      <th>Legalh</th>\n",
       "      <th>LSD</th>\n",
       "      <th>Meth</th>\n",
       "      <th>Mushrooms</th>\n",
       "      <th>Nicotine</th>\n",
       "      <th>VSA</th>\n",
       "      <th>Nscore (Real) [neuroticism]</th>\n",
       "      <th>Escore (Real) [Extraversion]</th>\n",
       "      <th>Oscore (Real) [Openness to experience]</th>\n",
       "      <th>Ascore (Real) [Agreeableness]</th>\n",
       "      <th>Cscore (Real) [Conscientiousness]</th>\n",
       "      <th>Impulsive (Real)</th>\n",
       "      <th>SS (Real) [sensation seeing (sic)]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.05188</td>\n",
       "      <td>-1.23177</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>0.25953</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>0.76540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.52135</td>\n",
       "      <td>0.32197</td>\n",
       "      <td>0.72330</td>\n",
       "      <td>0.13136</td>\n",
       "      <td>1.13407</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.52593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.24649</td>\n",
       "      <td>0.00332</td>\n",
       "      <td>1.06238</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>2.04506</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.52593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.05188</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>0.88309</td>\n",
       "      <td>0.13136</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>0.52975</td>\n",
       "      <td>0.07987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.28554</td>\n",
       "      <td>-1.23177</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>-2.53830</td>\n",
       "      <td>-2.90161</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>1.22470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.62967</td>\n",
       "      <td>-0.69509</td>\n",
       "      <td>0.14143</td>\n",
       "      <td>-1.21213</td>\n",
       "      <td>-0.27607</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.34799</td>\n",
       "      <td>0.00332</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>-0.15487</td>\n",
       "      <td>-0.52745</td>\n",
       "      <td>0.19268</td>\n",
       "      <td>1.22470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04257</td>\n",
       "      <td>-0.15487</td>\n",
       "      <td>-0.17779</td>\n",
       "      <td>-0.60633</td>\n",
       "      <td>-0.40581</td>\n",
       "      <td>1.86203</td>\n",
       "      <td>1.22470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13606</td>\n",
       "      <td>0.16767</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>0.43852</td>\n",
       "      <td>0.12331</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>0.40148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.02119</td>\n",
       "      <td>-2.03972</td>\n",
       "      <td>-0.71727</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>-1.25773</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>0.40148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1501 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      is_college_educated  is_high_school_dropout  <16 yrs old  16 yrs old  \\\n",
       "0                     0.0                     0.0          0.0         0.0   \n",
       "1                     1.0                     0.0          0.0         0.0   \n",
       "2                     1.0                     0.0          0.0         0.0   \n",
       "3                     1.0                     0.0          0.0         0.0   \n",
       "4                     0.0                     0.0          0.0         0.0   \n",
       "...                   ...                     ...          ...         ...   \n",
       "1496                  1.0                     0.0          0.0         0.0   \n",
       "1497                  0.0                     0.0          0.0         0.0   \n",
       "1498                  1.0                     0.0          0.0         0.0   \n",
       "1499                  1.0                     0.0          0.0         0.0   \n",
       "1500                  0.0                     0.0          0.0         0.0   \n",
       "\n",
       "      17 yrs old  18 yrs old  Some college or uni., no cert. or degree  \\\n",
       "0            0.0         0.0                                       1.0   \n",
       "1            0.0         0.0                                       0.0   \n",
       "2            0.0         0.0                                       0.0   \n",
       "3            0.0         0.0                                       0.0   \n",
       "4            0.0         0.0                                       1.0   \n",
       "...          ...         ...                                       ...   \n",
       "1496         0.0         0.0                                       0.0   \n",
       "1497         0.0         0.0                                       1.0   \n",
       "1498         0.0         0.0                                       0.0   \n",
       "1499         0.0         0.0                                       0.0   \n",
       "1500         0.0         0.0                                       1.0   \n",
       "\n",
       "      Prof. cert./diploma  Bachelor's  Master's  Ph.D.  18-24  25-34  35-44  \\\n",
       "0                     0.0         0.0       0.0    0.0    1.0    0.0    0.0   \n",
       "1                     0.0         0.0       1.0    0.0    0.0    1.0    0.0   \n",
       "2                     0.0         1.0       0.0    0.0    1.0    0.0    0.0   \n",
       "3                     0.0         1.0       0.0    0.0    0.0    1.0    0.0   \n",
       "4                     0.0         0.0       0.0    0.0    0.0    0.0    0.0   \n",
       "...                   ...         ...       ...    ...    ...    ...    ...   \n",
       "1496                  0.0         0.0       1.0    0.0    0.0    1.0    0.0   \n",
       "1497                  0.0         0.0       0.0    0.0    1.0    0.0    0.0   \n",
       "1498                  0.0         1.0       0.0    0.0    1.0    0.0    0.0   \n",
       "1499                  0.0         0.0       1.0    0.0    0.0    1.0    0.0   \n",
       "1500                  0.0         0.0       0.0    0.0    1.0    0.0    0.0   \n",
       "\n",
       "      45-54  55-64  65+  Gender (Real)  Alcohol  Amphet  Amyl  Benzos  Caff  \\\n",
       "0       0.0    0.0  0.0            1.0      1.0     0.0   0.0     0.0   1.0   \n",
       "1       0.0    0.0  0.0            1.0      1.0     1.0   0.0     0.0   1.0   \n",
       "2       0.0    0.0  0.0            1.0      1.0     0.0   0.0     0.0   1.0   \n",
       "3       0.0    0.0  0.0            1.0      1.0     0.0   0.0     0.0   1.0   \n",
       "4       1.0    0.0  0.0            0.0      0.0     0.0   0.0     1.0   1.0   \n",
       "...     ...    ...  ...            ...      ...     ...   ...     ...   ...   \n",
       "1496    0.0    0.0  0.0            0.0      1.0     0.0   1.0     1.0   1.0   \n",
       "1497    0.0    0.0  0.0            0.0      1.0     1.0   0.0     1.0   1.0   \n",
       "1498    0.0    0.0  0.0            0.0      1.0     0.0   0.0     0.0   1.0   \n",
       "1499    0.0    0.0  0.0            0.0      1.0     0.0   0.0     0.0   1.0   \n",
       "1500    0.0    0.0  0.0            0.0      1.0     1.0   0.0     1.0   1.0   \n",
       "\n",
       "      Cannabis  Choc  Coke  Crack  Ecstacy  Ketamine  Legalh  LSD  Meth  \\\n",
       "0          1.0   1.0   0.0    0.0      0.0       0.0     1.0  0.0   0.0   \n",
       "1          1.0   1.0   0.0    0.0      1.0       0.0     1.0  1.0   0.0   \n",
       "2          1.0   1.0   0.0    0.0      0.0       0.0     0.0  0.0   0.0   \n",
       "3          1.0   1.0   0.0    0.0      0.0       0.0     0.0  0.0   0.0   \n",
       "4          0.0   1.0   0.0    0.0      0.0       0.0     0.0  0.0   1.0   \n",
       "...        ...   ...   ...    ...      ...       ...     ...  ...   ...   \n",
       "1496       1.0   1.0   1.0    0.0      0.0       0.0     1.0  0.0   1.0   \n",
       "1497       1.0   1.0   1.0    1.0      1.0       0.0     1.0  1.0   1.0   \n",
       "1498       1.0   1.0   1.0    0.0      0.0       0.0     0.0  1.0   0.0   \n",
       "1499       1.0   1.0   1.0    0.0      0.0       0.0     0.0  0.0   1.0   \n",
       "1500       1.0   1.0   1.0    0.0      1.0       0.0     0.0  1.0   1.0   \n",
       "\n",
       "      Mushrooms  Nicotine  VSA  Nscore (Real) [neuroticism]  \\\n",
       "0           0.0       1.0  0.0                     -0.05188   \n",
       "1           0.0       0.0  0.0                      0.52135   \n",
       "2           0.0       0.0  0.0                     -0.24649   \n",
       "3           0.0       0.0  0.0                     -0.05188   \n",
       "4           0.0       0.0  0.0                      2.28554   \n",
       "...         ...       ...  ...                          ...   \n",
       "1496        1.0       1.0  1.0                      0.62967   \n",
       "1497        1.0       1.0  0.0                     -0.34799   \n",
       "1498        0.0       1.0  0.0                      0.04257   \n",
       "1499        0.0       1.0  0.0                      0.13606   \n",
       "1500        0.0       1.0  0.0                      1.02119   \n",
       "\n",
       "      Escore (Real) [Extraversion]  Oscore (Real) [Openness to experience]  \\\n",
       "0                         -1.23177                                 0.29338   \n",
       "1                          0.32197                                 0.72330   \n",
       "2                          0.00332                                 1.06238   \n",
       "3                          1.11406                                 0.88309   \n",
       "4                         -1.23177                                -0.01928   \n",
       "...                            ...                                     ...   \n",
       "1496                      -0.69509                                 0.14143   \n",
       "1497                       0.00332                                 0.58331   \n",
       "1498                      -0.15487                                -0.17779   \n",
       "1499                       0.16767                                -0.45174   \n",
       "1500                      -2.03972                                -0.71727   \n",
       "\n",
       "      Ascore (Real) [Agreeableness]  Cscore (Real) [Conscientiousness]  \\\n",
       "0                           1.11406                            0.25953   \n",
       "1                           0.13136                            1.13407   \n",
       "2                           0.59042                            2.04506   \n",
       "3                           0.13136                           -0.00665   \n",
       "4                          -2.53830                           -2.90161   \n",
       "...                             ...                                ...   \n",
       "1496                       -1.21213                           -0.27607   \n",
       "1497                       -0.15487                           -0.52745   \n",
       "1498                       -0.60633                           -0.40581   \n",
       "1499                        0.43852                            0.12331   \n",
       "1500                        1.11406                           -1.25773   \n",
       "\n",
       "      Impulsive (Real)  SS (Real) [sensation seeing (sic)]  \n",
       "0              0.88113                             0.76540  \n",
       "1             -0.21712                            -0.52593  \n",
       "2             -0.71126                            -0.52593  \n",
       "3              0.52975                             0.07987  \n",
       "4             -0.21712                             1.22470  \n",
       "...                ...                                 ...  \n",
       "1496          -0.21712                            -0.21575  \n",
       "1497           0.19268                             1.22470  \n",
       "1498           1.86203                             1.22470  \n",
       "1499          -0.71126                             0.40148  \n",
       "1500           0.88113                             0.40148  \n",
       "\n",
       "[1501 rows x 42 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pipeline that drops any samples with a 'Semer' value that is not CL0 and then drops the 'Semer' column\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('protect_xy', ProtectXy()),\n",
    "    ('drop_semer_samples', DropBadRowsTransformer('Semer', 'CL0')),\n",
    "    ('col_trans', ColumnTransformer(transformers=[\n",
    "        ('drop_unneeded', 'drop', ['Semer', 'ID',  'Country (Real)', 'Ethnicity (Real)']),\n",
    "        ('edu_feature_pl_college_educated', Pipeline(steps=[\n",
    "            ('convert_edu_real_values_to_human_readable_string_1', ConvertRealClassificationValuesToHumanReadableStrings(label_map=label_map_edu)),\n",
    "            ('add_new_feature_college_educated', IsCollegeEducated()),\n",
    "        ]), ['Education (Real)']),\n",
    "        ('edu_features_pl_highschool_dropout', Pipeline(steps=[\n",
    "            ('convert_edu_real_values_to_human_readable_string_1', ConvertRealClassificationValuesToHumanReadableStrings(label_map=label_map_edu)),\n",
    "            ('add_new_feature_highschool_dropout', IsHighSchoolDropout()),\n",
    "        ]), ['Education (Real)']),\n",
    "        ('edu_encoding_pl', Pipeline([\n",
    "            ('convert_edu_real_values_to_human_readable_string_2', ConvertRealClassificationValuesToHumanReadableStrings(label_map=label_map_edu)),\n",
    "            ('one_hot_encoding_edu', OneHotEncoder(drop=None, categories=[edu_labels])),\n",
    "        ]), ['Education (Real)']),\n",
    "        ('age', Pipeline([  \n",
    "            ('convert_age_real_values_to_human_readable_string', ConvertRealClassificationValuesToHumanReadableStrings(label_map=label_map_age)),\n",
    "            ('one_hot_encoding_age', OneHotEncoder(drop=None, categories=[age_labels])),\n",
    "        ]), ['Age (Real)']),\n",
    "        ('gender', Pipeline(steps=[\n",
    "            ('convert_gender_real_vals_to_binary', ConvertRealClassificationValuesToHumanReadableStrings(label_map=label_map_gender)),\n",
    "        ]), ['Gender (Real)']),\n",
    "        ('drug_classifications_to_users_pl', Pipeline(steps=[\n",
    "            ('classification_to_num_val', ClassifierToNumericalValueTransformer(features_to_apply_to=drug_labels, classifications_kept=user_classifications))]),\n",
    "        ['Alcohol', 'Amphet', 'Amyl', 'Benzos', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstacy', 'Ketamine', 'Legalh', 'LSD', 'Meth', 'Mushrooms', 'Nicotine', 'VSA']),\n",
    "    ], remainder='passthrough')),\n",
    "])\n",
    "X_trans = pd.DataFrame(pipeline.fit_transform(X_train, y_train), columns=labels_remaining)\n",
    "X_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 18:53:22.383186: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "data = X_trans.copy()\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "tensor = tf.convert_to_tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=tensor[0].shape))\n",
    "\n",
    "# Create the model using 2 hidden layers with 300 and 100 neurons using ReLU\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=tensor[0].shape, name=\"input\"),\n",
    "    keras.layers.Dense(300, activation=keras.activations.relu, name=\"hidden-1\"),\n",
    "    keras.layers.Dense(100, activation=keras.activations.relu, name=\"hidden-2\"),\n",
    "    keras.layers.Dense(10, activation=keras.activations.softmax, name=\"output\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
